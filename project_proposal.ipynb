{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import learning_curve\n",
    "from scipy.stats import randint as sp_randint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erik7brown/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/erik7brown/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Race</th>\n",
       "      <th>Num_Arrests</th>\n",
       "      <th>State</th>\n",
       "      <th>CensusTract</th>\n",
       "      <th>County</th>\n",
       "      <th>Borough</th>\n",
       "      <th>TotalPop</th>\n",
       "      <th>Men</th>\n",
       "      <th>Women</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>...</th>\n",
       "      <th>Walk</th>\n",
       "      <th>OtherTransp</th>\n",
       "      <th>WorkAtHome</th>\n",
       "      <th>MeanCommute</th>\n",
       "      <th>Employed</th>\n",
       "      <th>PrivateWork</th>\n",
       "      <th>PublicWork</th>\n",
       "      <th>SelfEmployed</th>\n",
       "      <th>FamilyWork</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NY</td>\n",
       "      <td>36085024402</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>4241</td>\n",
       "      <td>2023</td>\n",
       "      <td>2218</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.3</td>\n",
       "      <td>2046</td>\n",
       "      <td>75.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NY</td>\n",
       "      <td>36085024402</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>4241</td>\n",
       "      <td>2023</td>\n",
       "      <td>2218</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.3</td>\n",
       "      <td>2046</td>\n",
       "      <td>75.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NY</td>\n",
       "      <td>36085024402</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>4241</td>\n",
       "      <td>2023</td>\n",
       "      <td>2218</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.3</td>\n",
       "      <td>2046</td>\n",
       "      <td>75.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NY</td>\n",
       "      <td>36085024402</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>4241</td>\n",
       "      <td>2023</td>\n",
       "      <td>2218</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.3</td>\n",
       "      <td>2046</td>\n",
       "      <td>75.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NY</td>\n",
       "      <td>36085024402</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>4241</td>\n",
       "      <td>2023</td>\n",
       "      <td>2218</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.3</td>\n",
       "      <td>2046</td>\n",
       "      <td>75.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NY</td>\n",
       "      <td>36085024402</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>4241</td>\n",
       "      <td>2023</td>\n",
       "      <td>2218</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.3</td>\n",
       "      <td>2046</td>\n",
       "      <td>75.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NY</td>\n",
       "      <td>36085024401</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>6408</td>\n",
       "      <td>2755</td>\n",
       "      <td>3653</td>\n",
       "      <td>8.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>44.6</td>\n",
       "      <td>2703</td>\n",
       "      <td>70.2</td>\n",
       "      <td>29.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Race  Num_Arrests State  CensusTract    County        Borough  TotalPop  \\\n",
       "0     0            1    NY  36085024402  Richmond  Staten Island      4241   \n",
       "1     0            4    NY  36085024402  Richmond  Staten Island      4241   \n",
       "2     0            1    NY  36085024402  Richmond  Staten Island      4241   \n",
       "3     0            1    NY  36085024402  Richmond  Staten Island      4241   \n",
       "4     0            2    NY  36085024402  Richmond  Staten Island      4241   \n",
       "5     1            1    NY  36085024402  Richmond  Staten Island      4241   \n",
       "6     0            3    NY  36085024401  Richmond  Staten Island      6408   \n",
       "\n",
       "    Men  Women  Hispanic  ...  Walk  OtherTransp  WorkAtHome  MeanCommute  \\\n",
       "0  2023   2218       3.7  ...   1.1          0.6         4.0         44.3   \n",
       "1  2023   2218       3.7  ...   1.1          0.6         4.0         44.3   \n",
       "2  2023   2218       3.7  ...   1.1          0.6         4.0         44.3   \n",
       "3  2023   2218       3.7  ...   1.1          0.6         4.0         44.3   \n",
       "4  2023   2218       3.7  ...   1.1          0.6         4.0         44.3   \n",
       "5  2023   2218       3.7  ...   1.1          0.6         4.0         44.3   \n",
       "6  2755   3653       8.3  ...   0.1          0.0         3.9         44.6   \n",
       "\n",
       "   Employed  PrivateWork  PublicWork  SelfEmployed  FamilyWork  Unemployment  \n",
       "0      2046         75.2        21.2           3.6         0.0           8.3  \n",
       "1      2046         75.2        21.2           3.6         0.0           8.3  \n",
       "2      2046         75.2        21.2           3.6         0.0           8.3  \n",
       "3      2046         75.2        21.2           3.6         0.0           8.3  \n",
       "4      2046         75.2        21.2           3.6         0.0           8.3  \n",
       "5      2046         75.2        21.2           3.6         0.0           8.3  \n",
       "6      2703         70.2        29.3           0.6         0.0           6.6  \n",
       "\n",
       "[7 rows x 39 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrest_data = pd.read_csv(\"arrests_w_census_loc.csv\")\n",
    "arrest_data.PERP_RACE[arrest_data.PERP_RACE.str.contains(\"WHITE\")]=0\n",
    "arrest_data.PERP_RACE[arrest_data.PERP_RACE != 0]=1\n",
    "arrest_data = arrest_data.groupby([\"PERP_RACE\",\"BlockLocation\"]).size().reset_index(name='counts')\n",
    "blockLocation = arrest_data[\"BlockLocation\"]\n",
    "blockLat = [float(re.findall(r'[-\\d\\.]+', bl)[0]) for bl in blockLocation]\n",
    "blockLon = [float(re.findall(r'[-\\d\\.]+', bl)[1]) for bl in blockLocation]\n",
    "arrest_data[\"blockLat\"]=blockLat\n",
    "arrest_data[\"blockLon\"]=blockLon\n",
    "arrest_data = arrest_data.drop(\"BlockLocation\", axis=1)\n",
    "arrest_data = arrest_data.rename(columns={\"counts\": \"Num_Arrests\", \"PERP_RACE\": \"Race\"})\n",
    "block_data = pd.read_csv(\"census_block_loc.csv\")\n",
    "block_data = pd.merge(left=arrest_data, right=block_data,\n",
    "                      left_on=[\"blockLat\",\"blockLon\"], right_on=[\"Latitude\",\"Longitude\"])\n",
    "census_data = pd.read_csv(\"nyc_census_tracts.csv\")\n",
    "tracts = block_data[\"BlockCode\"]\n",
    "tracts = [int(str(tract)[:-4]) for tract in tracts]\n",
    "block_data[\"tracts\"]=tracts\n",
    "block_data = block_data.drop(columns=[\"Latitude\",\"Longitude\",\"BlockCode\",\"County\",\"blockLat\",\"blockLon\"])\n",
    "data = pd.merge(left=block_data, right=census_data, left_on=\"tracts\", right_on=\"CensusTract\")\n",
    "data = data.drop(\"tracts\", axis=1)\n",
    "data.head(n=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10955, 39)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data.sample(frac=0.7,random_state=200) #meant to randomly grab 70% of data by row for test\n",
    "data_test  = data.drop(data_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = data.shape[1] #num columns\n",
    "\n",
    "X = data_train.iloc[:,0:cols-1] # iloc slicing function , split the data into X and Y\n",
    "y = data_train.iloc[:,cols-1:cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Race', 'Num_Arrests', 'State', 'CensusTract', 'County', 'Borough',\n",
       "       'TotalPop', 'Men', 'Women', 'Hispanic', 'White', 'Black', 'Native',\n",
       "       'Asian', 'Citizen', 'Income', 'IncomeErr', 'IncomePerCap',\n",
       "       'IncomePerCapErr', 'Poverty', 'ChildPoverty', 'Professional', 'Service',\n",
       "       'Office', 'Construction', 'Production', 'Drive', 'Carpool', 'Transit',\n",
       "       'Walk', 'OtherTransp', 'WorkAtHome', 'MeanCommute', 'Employed',\n",
       "       'PrivateWork', 'PublicWork', 'SelfEmployed', 'FamilyWork'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(my_kernel,X,y):\n",
    "    clf = SVR(kernel = my_kernel, gamma='auto')\n",
    "    clf.fit(X,y)\n",
    "    print('================'+str(my_kernel)+'==================')\n",
    "    cross_val(clf, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(clf, X, y ):\n",
    "    CV = KFold(n_splits=50, random_state=None, shuffle=False)\n",
    "    y_pred = cross_val_predict(clf, X, y, cv = CV)\n",
    "    print('Classification Report: \\n')\n",
    "    print(metrics.classification_report(y, y_pred, sample_weight = y,labels=np.unique(y_pred)))\n",
    "    print('\\nConfusion Matrix: ')\n",
    "    print(metrics.confusion_matrix(y, y_pred, sample_weight = y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONT RUN THIS ONE UNTIL READY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Manhattan'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-98f625b78ebf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mCV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkernal\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkernals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-51ab1e4dbdbc>\u001b[0m in \u001b[0;36mmodel_fit\u001b[0;34m(my_kernel, X, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_kernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'================'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_kernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'=================='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcross_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    144\u001b[0m         X, y = check_X_y(X, y, dtype=np.float64,\n\u001b[1;32m    145\u001b[0m                          \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                          accept_large_sparse=False)\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    720\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Manhattan'"
     ]
    }
   ],
   "source": [
    "kernals = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "CV = 10\n",
    "for kernal in kernals:\n",
    "    model_fit(kernal,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Non-White'] = 100 - X['White']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['Hispanic','Black','Native','Asian'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
