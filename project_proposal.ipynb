{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(42)#set  random seed for reproducability\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TestAccount\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\TestAccount\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Race</th>\n",
       "      <th>Num_Arrests</th>\n",
       "      <th>CensusTract</th>\n",
       "      <th>County</th>\n",
       "      <th>Borough</th>\n",
       "      <th>TotalPop</th>\n",
       "      <th>Men</th>\n",
       "      <th>Women</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>White</th>\n",
       "      <th>...</th>\n",
       "      <th>Walk</th>\n",
       "      <th>OtherTransp</th>\n",
       "      <th>WorkAtHome</th>\n",
       "      <th>MeanCommute</th>\n",
       "      <th>Employed</th>\n",
       "      <th>PrivateWork</th>\n",
       "      <th>PublicWork</th>\n",
       "      <th>SelfEmployed</th>\n",
       "      <th>FamilyWork</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36085024402</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>4241</td>\n",
       "      <td>2023</td>\n",
       "      <td>2218</td>\n",
       "      <td>3.7</td>\n",
       "      <td>84.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.3</td>\n",
       "      <td>2046</td>\n",
       "      <td>75.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>36085024402</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>4241</td>\n",
       "      <td>2023</td>\n",
       "      <td>2218</td>\n",
       "      <td>3.7</td>\n",
       "      <td>84.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.3</td>\n",
       "      <td>2046</td>\n",
       "      <td>75.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36085024402</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>4241</td>\n",
       "      <td>2023</td>\n",
       "      <td>2218</td>\n",
       "      <td>3.7</td>\n",
       "      <td>84.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.3</td>\n",
       "      <td>2046</td>\n",
       "      <td>75.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36085024402</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>4241</td>\n",
       "      <td>2023</td>\n",
       "      <td>2218</td>\n",
       "      <td>3.7</td>\n",
       "      <td>84.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.3</td>\n",
       "      <td>2046</td>\n",
       "      <td>75.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36085024402</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>4241</td>\n",
       "      <td>2023</td>\n",
       "      <td>2218</td>\n",
       "      <td>3.7</td>\n",
       "      <td>84.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.3</td>\n",
       "      <td>2046</td>\n",
       "      <td>75.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11336</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>36005044800</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>2181</td>\n",
       "      <td>1092</td>\n",
       "      <td>1089</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1233</td>\n",
       "      <td>77.9</td>\n",
       "      <td>19.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11337</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>36005044800</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>2181</td>\n",
       "      <td>1092</td>\n",
       "      <td>1089</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1233</td>\n",
       "      <td>77.9</td>\n",
       "      <td>19.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11338</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>36005044800</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>2181</td>\n",
       "      <td>1092</td>\n",
       "      <td>1089</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1233</td>\n",
       "      <td>77.9</td>\n",
       "      <td>19.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11339</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>36005043000</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>3321</td>\n",
       "      <td>1380</td>\n",
       "      <td>1941</td>\n",
       "      <td>16.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.2</td>\n",
       "      <td>1466</td>\n",
       "      <td>76.2</td>\n",
       "      <td>22.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11340</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>36005043000</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>3321</td>\n",
       "      <td>1380</td>\n",
       "      <td>1941</td>\n",
       "      <td>16.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.2</td>\n",
       "      <td>1466</td>\n",
       "      <td>76.2</td>\n",
       "      <td>22.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11341 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Race  Num_Arrests  CensusTract    County        Borough  TotalPop  \\\n",
       "0         0            1  36085024402  Richmond  Staten Island      4241   \n",
       "1         0            4  36085024402  Richmond  Staten Island      4241   \n",
       "2         0            1  36085024402  Richmond  Staten Island      4241   \n",
       "3         0            1  36085024402  Richmond  Staten Island      4241   \n",
       "4         0            1  36085024402  Richmond  Staten Island      4241   \n",
       "...     ...          ...          ...       ...            ...       ...   \n",
       "11336     1            2  36005044800     Bronx          Bronx      2181   \n",
       "11337     1            2  36005044800     Bronx          Bronx      2181   \n",
       "11338     1            2  36005044800     Bronx          Bronx      2181   \n",
       "11339     1            5  36005043000     Bronx          Bronx      3321   \n",
       "11340     1            6  36005043000     Bronx          Bronx      3321   \n",
       "\n",
       "        Men  Women  Hispanic  White  ...  Walk  OtherTransp  WorkAtHome  \\\n",
       "0      2023   2218       3.7   84.5  ...   1.1          0.6         4.0   \n",
       "1      2023   2218       3.7   84.5  ...   1.1          0.6         4.0   \n",
       "2      2023   2218       3.7   84.5  ...   1.1          0.6         4.0   \n",
       "3      2023   2218       3.7   84.5  ...   1.1          0.6         4.0   \n",
       "4      2023   2218       3.7   84.5  ...   1.1          0.6         4.0   \n",
       "...     ...    ...       ...    ...  ...   ...          ...         ...   \n",
       "11336  1092   1089       9.9    1.6  ...   2.8          0.0         0.0   \n",
       "11337  1092   1089       9.9    1.6  ...   2.8          0.0         0.0   \n",
       "11338  1092   1089       9.9    1.6  ...   2.8          0.0         0.0   \n",
       "11339  1380   1941      16.2    2.2  ...   5.5          0.0         0.0   \n",
       "11340  1380   1941      16.2    2.2  ...   5.5          0.0         0.0   \n",
       "\n",
       "       MeanCommute  Employed  PrivateWork  PublicWork  SelfEmployed  \\\n",
       "0             44.3      2046         75.2        21.2           3.6   \n",
       "1             44.3      2046         75.2        21.2           3.6   \n",
       "2             44.3      2046         75.2        21.2           3.6   \n",
       "3             44.3      2046         75.2        21.2           3.6   \n",
       "4             44.3      2046         75.2        21.2           3.6   \n",
       "...            ...       ...          ...         ...           ...   \n",
       "11336         49.0      1233         77.9        19.6           2.5   \n",
       "11337         49.0      1233         77.9        19.6           2.5   \n",
       "11338         49.0      1233         77.9        19.6           2.5   \n",
       "11339         38.2      1466         76.2        22.4           1.4   \n",
       "11340         38.2      1466         76.2        22.4           1.4   \n",
       "\n",
       "       FamilyWork  Unemployment  \n",
       "0             0.0           8.3  \n",
       "1             0.0           8.3  \n",
       "2             0.0           8.3  \n",
       "3             0.0           8.3  \n",
       "4             0.0           8.3  \n",
       "...           ...           ...  \n",
       "11336         0.0          10.7  \n",
       "11337         0.0          10.7  \n",
       "11338         0.0          10.7  \n",
       "11339         0.0           9.5  \n",
       "11340         0.0           9.5  \n",
       "\n",
       "[11341 rows x 38 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrest_data = pd.read_csv(\"arrests_w_census_loc.csv\")\n",
    "arrest_data.PERP_RACE[arrest_data.PERP_RACE.str.contains(\"WHITE\")]=0\n",
    "arrest_data.PERP_RACE[arrest_data.PERP_RACE != 0]=1\n",
    "arrest_data = arrest_data.groupby([\"PERP_RACE\",\"BlockLocation\"]).size().reset_index(name='counts')\n",
    "blockLocation = arrest_data[\"BlockLocation\"]\n",
    "blockLat = [float(re.findall(r'[-\\d\\.]+', bl)[0]) for bl in blockLocation]\n",
    "blockLon = [float(re.findall(r'[-\\d\\.]+', bl)[1]) for bl in blockLocation]\n",
    "arrest_data[\"blockLat\"]=blockLat\n",
    "arrest_data[\"blockLon\"]=blockLon\n",
    "arrest_data = arrest_data.drop(\"BlockLocation\", axis=1)\n",
    "arrest_data = arrest_data.rename(columns={\"counts\": \"Num_Arrests\", \"PERP_RACE\": \"Race\"})\n",
    "block_data = pd.read_csv(\"census_block_loc.csv\")\n",
    "block_data = pd.merge(left=arrest_data, right=block_data,\n",
    "                      left_on=[\"blockLat\",\"blockLon\"], right_on=[\"Latitude\",\"Longitude\"])\n",
    "census_data = pd.read_csv(\"nyc_census_tracts.csv\")\n",
    "tracts = block_data[\"BlockCode\"]\n",
    "tracts = [int(str(tract)[:-4]) for tract in tracts]\n",
    "block_data[\"tracts\"]=tracts\n",
    "block_data = block_data.drop(columns=[\"Latitude\",\"Longitude\",\"BlockCode\",\"County\",\"blockLat\",\"blockLon\"])\n",
    "data = pd.merge(left=block_data, right=census_data, left_on=\"tracts\", right_on=\"CensusTract\")\n",
    "data = data.drop(\"tracts\", axis=1)\n",
    "data = data.drop(\"State\", axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Outlier Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11341 Samples Before Outlier Removal\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10735 Samples After Outlier Removal\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.65655585927166% of Samples were Kept\n"
     ]
    }
   ],
   "source": [
    "data[\"Num_Arrests\"].hist(bins='auto')\n",
    "data_size=data.shape[0]\n",
    "print(\"There are\",data_size,\"Samples Before Outlier Removal\")\n",
    "plt.show()\n",
    "#cuttoff data after 20\n",
    "data = data[data[\"Num_Arrests\"]<30]\n",
    "new_size=data.shape[0]\n",
    "print(\"There are\",new_size,\"Samples After Outlier Removal\")\n",
    "data[\"Num_Arrests\"].hist(bins='auto')\n",
    "plt.show()\n",
    "print(100*new_size/data_size,\"% of Samples were Kept\",sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data Aggregates by County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_all(data):\n",
    "    new_data = {}\n",
    "    for colname in ['Num_Arrests','TotalPop','Men','Women','Citizen','Income','IncomeErr', 'Employed']:\n",
    "        new_data[colname]=data[colname].sum()\n",
    "    for colname in ['Hispanic', 'White', 'Black', 'Native', 'Asian','IncomePerCap','IncomePerCapErr','Poverty', 'ChildPoverty', 'Professional', 'Service', 'Office',\n",
    "            'Construction', 'Production', 'Drive', 'Carpool', 'Transit', 'Walk','OtherTransp', 'WorkAtHome',\n",
    "           'MeanCommute','PrivateWork','PublicWork','SelfEmployed','FamilyWork','Unemployment']:\n",
    "        ratio = data[colname]*data['TotalPop']\n",
    "        new_data[colname]=(ratio.sum()/100)/data.size\n",
    "    return pd.Series(new_data)\n",
    "\n",
    "agg_data = data.groupby(['County','Race']).apply(agg_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attatch Aggregate to Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Race</th>\n",
       "      <th>Num_Arrests</th>\n",
       "      <th>CensusTract</th>\n",
       "      <th>County</th>\n",
       "      <th>Borough</th>\n",
       "      <th>TotalPop</th>\n",
       "      <th>Men</th>\n",
       "      <th>Women</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>White</th>\n",
       "      <th>...</th>\n",
       "      <th>OtherTransp</th>\n",
       "      <th>WorkAtHome</th>\n",
       "      <th>MeanCommute</th>\n",
       "      <th>Employed</th>\n",
       "      <th>PrivateWork</th>\n",
       "      <th>PublicWork</th>\n",
       "      <th>SelfEmployed</th>\n",
       "      <th>FamilyWork</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>County_Num_Arrests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36085024402</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>4241</td>\n",
       "      <td>2023</td>\n",
       "      <td>2218</td>\n",
       "      <td>3.7</td>\n",
       "      <td>84.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.3</td>\n",
       "      <td>2046</td>\n",
       "      <td>75.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2.147308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>36085024402</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>4241</td>\n",
       "      <td>2023</td>\n",
       "      <td>2218</td>\n",
       "      <td>3.7</td>\n",
       "      <td>84.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.3</td>\n",
       "      <td>2046</td>\n",
       "      <td>75.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2.147308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36085024402</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>4241</td>\n",
       "      <td>2023</td>\n",
       "      <td>2218</td>\n",
       "      <td>3.7</td>\n",
       "      <td>84.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.3</td>\n",
       "      <td>2046</td>\n",
       "      <td>75.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2.147308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36085024402</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>4241</td>\n",
       "      <td>2023</td>\n",
       "      <td>2218</td>\n",
       "      <td>3.7</td>\n",
       "      <td>84.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.3</td>\n",
       "      <td>2046</td>\n",
       "      <td>75.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2.147308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36085024402</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>4241</td>\n",
       "      <td>2023</td>\n",
       "      <td>2218</td>\n",
       "      <td>3.7</td>\n",
       "      <td>84.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.3</td>\n",
       "      <td>2046</td>\n",
       "      <td>75.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2.147308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Race  Num_Arrests  CensusTract    County        Borough  TotalPop   Men  \\\n",
       "0     0            1  36085024402  Richmond  Staten Island      4241  2023   \n",
       "1     0            4  36085024402  Richmond  Staten Island      4241  2023   \n",
       "2     0            1  36085024402  Richmond  Staten Island      4241  2023   \n",
       "3     0            1  36085024402  Richmond  Staten Island      4241  2023   \n",
       "4     0            1  36085024402  Richmond  Staten Island      4241  2023   \n",
       "\n",
       "   Women  Hispanic  White  ...  OtherTransp  WorkAtHome  MeanCommute  \\\n",
       "0   2218       3.7   84.5  ...          0.6         4.0         44.3   \n",
       "1   2218       3.7   84.5  ...          0.6         4.0         44.3   \n",
       "2   2218       3.7   84.5  ...          0.6         4.0         44.3   \n",
       "3   2218       3.7   84.5  ...          0.6         4.0         44.3   \n",
       "4   2218       3.7   84.5  ...          0.6         4.0         44.3   \n",
       "\n",
       "   Employed  PrivateWork  PublicWork  SelfEmployed  FamilyWork  Unemployment  \\\n",
       "0      2046         75.2        21.2           3.6         0.0           8.3   \n",
       "1      2046         75.2        21.2           3.6         0.0           8.3   \n",
       "2      2046         75.2        21.2           3.6         0.0           8.3   \n",
       "3      2046         75.2        21.2           3.6         0.0           8.3   \n",
       "4      2046         75.2        21.2           3.6         0.0           8.3   \n",
       "\n",
       "   County_Num_Arrests  \n",
       "0            2.147308  \n",
       "1            2.147308  \n",
       "2            2.147308  \n",
       "3            2.147308  \n",
       "4            2.147308  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agg_data[\"arrest_ratio\"]=agg_data[\"Num_Arrests\"]/agg_data[\"TotalPop\"]\n",
    "arrest_ratio = list(agg_data[\"arrest_ratio\"])\n",
    "county = list(agg_data.index.get_level_values(0))\n",
    "race = list(agg_data.index.get_level_values(1))\n",
    "agg_data = pd.DataFrame(arrest_ratio, columns=[\"arrest_ratio\"])\n",
    "agg_data[\"County\"]=county\n",
    "agg_data[\"Race\"]=race\n",
    "data = pd.merge(data, agg_data, on=[\"County\",\"Race\"])\n",
    "data[\"County_Num_Arrests\"]=data[\"arrest_ratio\"]*data[\"TotalPop\"]\n",
    "data = data.drop(\"arrest_ratio\", axis=1)\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth Data Between Aggregate and Un-Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_data = pd.read_csv(\"census_block_loc.csv\")\n",
    "block_data = block_data.drop(columns=[\"BlockCode\",\"County\",\"State\"])\n",
    "block_data[\"Raw_Arrests\"]=np.random.normal(scale=10,size=block_data.shape[0])\n",
    "block_data[\"County_Arrests\"]=np.random.normal(scale=1,size=block_data.shape[0])\n",
    "block_data[\"Smoothed_Arrests\"]=np.random.normal(scale=5,size=block_data.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Visualize Num_Arrests, County_Num_Arrests, and Smoothed Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put in visuals here from the dataset \"block_data\"\n",
    "#real data will be replaced when Erik figures out the proper way to do the smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Z Scaling to Continuous Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['TotalPop','Men','Women','Hispanic','White','Black','Native','Asian','Citizen','Income','IncomeErr','IncomePerCap','IncomePerCapErr','Poverty','ChildPoverty','Professional','Service','Office','Construction','Production','Drive','Carpool','Transit','Walk','OtherTransp','WorkAtHome','MeanCommute','Employed','PrivateWork','PublicWork','SelfEmployed','FamilyWork','Unemployment']\n",
    "X = data[num_cols].values\n",
    "data.drop(columns=num_cols)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "num_data = pd.DataFrame(X, columns=num_cols)\n",
    "data[num_cols]=num_data\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data by Race and Into Train/Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = data.shape[1]\n",
    "data_white = data[data[\"Race\"]==0].drop(\"Race\", axis=1)\n",
    "data_non_white=data[data[\"Race\"]==1].drop(\"Race\", axis=1)\n",
    "data_white_train = data_white.sample(frac=0.8,random_state=101)\n",
    "data_white_test  = data_white.drop(data_white_train.index)\n",
    "data_non_white_train = data_non_white.sample(frac=0.8,random_state=101)\n",
    "data_non_white_test  = data_non_white.drop(data_non_white_train.index)\n",
    "Xw = data_white_train.iloc[:,1:cols]\n",
    "yw = data_white_train.iloc[:,0]\n",
    "Xnw = data_non_white_train.iloc[:,1:cols]\n",
    "ynw = data_non_white_train.iloc[:,0]\n",
    "Xwt = data_white_test.iloc[:,1:cols]\n",
    "ywt = data_white_test.iloc[:,0]\n",
    "Xnwt = data_non_white_test.iloc[:,1:cols]\n",
    "ynwt = data_non_white_test.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Categorical Features as Numerical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['CensusTract','County','Borough']\n",
    "encoder = LabelEncoder()\n",
    "for var in cat_cols:\n",
    "    Xw[var] = encoder.fit_transform(Xw[var])\n",
    "    Xnw[var] = encoder.fit_transform(Xnw[var])\n",
    "    Xwt[var] = encoder.fit_transform(Xwt[var])\n",
    "    Xnwt[var] = encoder.fit_transform(Xnwt[var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Test of Nonlinear Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average MSE for White RBF is 25.961481123505003\n",
      "The average MSE for Non-White RBF is 42.32344659816731\n",
      "The average MSE for White Polynomial is 25.814859067500542\n",
      "The average MSE for Non-White Polynomial is 42.87101766355538\n"
     ]
    }
   ],
   "source": [
    "rbfw = SVR(gamma='scale',kernel='rbf')\n",
    "cv = cross_val_score(rbfw, Xw, yw, cv=50, scoring=\"neg_mean_squared_error\")\n",
    "print(\"The average MSE for White RBF is\",-sum(cv)/len(cv))\n",
    "\n",
    "rbfnw = SVR(gamma='scale',kernel='rbf')\n",
    "cv = cross_val_score(rbfnw, Xnw, ynw, cv=50, scoring=\"neg_mean_squared_error\")\n",
    "print(\"The average MSE for Non-White RBF is\",-sum(cv)/len(cv))\n",
    "\n",
    "polyw = SVR(gamma='scale',kernel='poly')\n",
    "cv = cross_val_score(polyw, Xw, yw, cv=50, scoring=\"neg_mean_squared_error\")\n",
    "print(\"The average MSE for White Polynomial is\",-sum(cv)/len(cv))\n",
    "\n",
    "polynw = SVR(gamma='scale',kernel='poly')\n",
    "cv = cross_val_score(polynw, Xnw, ynw, cv=50, scoring=\"neg_mean_squared_error\")\n",
    "print(\"The average MSE for Non-White Polynomial is\",-sum(cv)/len(cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search to Tune Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal white C 500\n",
      "optimal white epsilon 1.0910448648414965\n",
      "optimal white kernel rbf\n",
      "optimal non-white C 1000\n",
      "optimal non-white epsilon 2.6259597935782515\n",
      "optimal non-white kernel rbf\n"
     ]
    }
   ],
   "source": [
    "params = {\"C\":[0.1,0.5,1,5,10,50,100,500,1000],\"epsilon\":uniform(1,3),\"kernel\":[\"poly\",\"rbf\"]}\n",
    "\n",
    "rscv = RandomizedSearchCV(SVR(gamma=\"scale\"),params,cv=50,iid=False)\n",
    "rscv.fit(Xw,yw)\n",
    "print(\"optimal white C\", rscv.best_estimator_.get_params()[\"C\"])\n",
    "print(\"optimal white epsilon\", rscv.best_estimator_.get_params()[\"epsilon\"])\n",
    "print(\"optimal white kernel\", rscv.best_estimator_.get_params()[\"kernel\"])\n",
    "\n",
    "rscv2 = RandomizedSearchCV(SVR(gamma=\"scale\"),params,cv=50,iid=False)\n",
    "rscv2.fit(Xnw,ynw)\n",
    "print(\"optimal non-white C\", rscv2.best_estimator_.get_params()[\"C\"])\n",
    "print(\"optimal non-white epsilon\", rscv2.best_estimator_.get_params()[\"epsilon\"])\n",
    "print(\"optimal non-white kernel\", rscv2.best_estimator_.get_params()[\"kernel\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE for White:  22.599631771725846\n",
      "Test MAE for White:  2.922924840204984\n",
      "Test MSE for Non-White:  31.391169452782947\n",
      "Test MAE for Non-White:  3.8686288382759195\n"
     ]
    }
   ],
   "source": [
    "Final_model = SVR(kernel='rbf', C=750, gamma=\"scale\", epsilon=1.5)\n",
    "Final_model.fit(Xw, yw)\n",
    "test_predicted = Final_model.predict(Xwt)\n",
    "mse = mean_squared_error(ywt, test_predicted)\n",
    "print(\"Test MSE for White: \",mse)\n",
    "mae = mean_absolute_error(ywt, test_predicted)\n",
    "print(\"Test MAE for White: \",mae)\n",
    "Final_model.fit(Xnw, ynw)\n",
    "test_predicted_2 = Final_model.predict(Xnwt)\n",
    "mse = mean_squared_error(ynwt, test_predicted_2)\n",
    "print(\"Test MSE for Non-White: \",mse)\n",
    "mae = mean_absolute_error(ynwt, test_predicted_2)\n",
    "print(\"Test MAE for Non-White: \",mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TestAccount\\Miniconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average MSE for White is 21.09364132212654\n",
      "The average MSE for Non-White is 32.210134068711675\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "model.fit(Xw, yw)\n",
    "cv = cross_val_score(model, Xw, yw, cv=50, scoring=\"neg_mean_squared_error\")\n",
    "print(\"The average MSE for White is\",-sum(cv)/len(cv))\n",
    "model.fit(Xnw, ynw)\n",
    "cv = cross_val_score(model, Xnw, ynw, cv=50, scoring=\"neg_mean_squared_error\")\n",
    "print(\"The average MSE for Non-White is\",-sum(cv)/len(cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Random Forrest Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal min_samples_split 25\n",
      "optimal max_features 20\n",
      "optimal min_samples_split 20\n",
      "optimal max_features 5\n"
     ]
    }
   ],
   "source": [
    "params = {\"min_samples_split\":[2,5,10,15,20,25,30,35], \"max_features\":[5,10,15,20,25,30]}\n",
    "\n",
    "rscv = RandomizedSearchCV(RandomForestRegressor(n_estimators=500),params,cv=50,iid=False)\n",
    "rscv.fit(Xw,yw)\n",
    "print(\"optimal min_samples_split\", rscv.best_estimator_.get_params()[\"min_samples_split\"])\n",
    "print(\"optimal max_features\", rscv.best_estimator_.get_params()[\"max_features\"])\n",
    "\n",
    "rscv2 = RandomizedSearchCV(RandomForestRegressor(n_estimators=500),params,cv=50,iid=False)\n",
    "rscv2.fit(Xnw,ynw)\n",
    "print(\"optimal min_samples_split\", rscv2.best_estimator_.get_params()[\"min_samples_split\"])\n",
    "print(\"optimal max_features\", rscv2.best_estimator_.get_params()[\"max_features\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Test Data From Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE for White:  19.381490716871955\n",
      "Test MAE for White:  2.9939469565369548\n",
      "Test MSE for Non-White:  23.471971846036553\n",
      "Test MAE for Non-White:  3.6176315832912267\n"
     ]
    }
   ],
   "source": [
    "Final_model = RandomForestRegressor(n_estimators=500, min_samples_split=25, max_features=10)\n",
    "Final_model.fit(Xw, yw)\n",
    "test_predicted = Final_model.predict(Xwt)\n",
    "mse = mean_squared_error(ywt, test_predicted)\n",
    "print(\"Test MSE for White: \",mse)\n",
    "mae = mean_absolute_error(ywt, test_predicted)\n",
    "print(\"Test MAE for White: \",mae)\n",
    "Final_model.fit(Xnw, ynw)\n",
    "test_predicted_2 = Final_model.predict(Xnwt)\n",
    "mse = mean_squared_error(ynwt, test_predicted_2)\n",
    "print(\"Test MSE for Non-White: \",mse)\n",
    "mae = mean_absolute_error(ynwt, test_predicted_2)\n",
    "print(\"Test MAE for Non-White: \",mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Bias Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_model.fit(Xw, yw)\n",
    "Xw[\"predicted_w\"] = Final_model.predict(Xw)\n",
    "Final_model.fit(Xnw, ynw)\n",
    "Xnw[\"predicted_nw\"] = Final_model.predict(Xnw)\n",
    "Xnw = Xnw[[\"CensusTract\", \"predicted_nw\"]]\n",
    "X = pd.merge(left=Xw, right=Xnw,left_on=\"CensusTract\", right_on=\"CensusTract\")\n",
    "X[\"Non-White\"]=1-X[\"White\"]\n",
    "X[\"y\"] = np.log(abs(X[\"predicted_w\"]/X[\"White\"]-X[\"predicted_nw\"]/X[\"Non-White\"]))\n",
    "X = X.replace(np.inf, np.nan)\n",
    "X = X.dropna()\n",
    "X_train = X.sample(frac=0.8,random_state=101)\n",
    "Xt=X.drop(X_train.index)\n",
    "X=X_train\n",
    "y = X[\"y\"]\n",
    "yt=Xt[\"y\"]\n",
    "X = X.drop(columns=['Hispanic','Black','Native','Asian',\"White\",\"Non-White\",\"y\"])\n",
    "Xt = Xt.drop(columns=['Hispanic','Black','Native','Asian',\"White\",\"Non-White\",\"y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Multi-Layer Perceptron To Bias Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7982/7982 [==============================] - 0s 59us/step - loss: 231.3992 - mean_squared_error: 231.3993 - mean_absolute_error: 4.8388\n",
      "Epoch 2/100\n",
      "7982/7982 [==============================] - 0s 29us/step - loss: 0.9436 - mean_squared_error: 0.9436 - mean_absolute_error: 0.6663\n",
      "Epoch 3/100\n",
      "7982/7982 [==============================] - 0s 29us/step - loss: 0.8749 - mean_squared_error: 0.8749 - mean_absolute_error: 0.6375\n",
      "Epoch 4/100\n",
      "7982/7982 [==============================] - 0s 35us/step - loss: 0.8574 - mean_squared_error: 0.8574 - mean_absolute_error: 0.6301\n",
      "Epoch 5/100\n",
      "7982/7982 [==============================] - 0s 31us/step - loss: 0.8510 - mean_squared_error: 0.8510 - mean_absolute_error: 0.6296\n",
      "Epoch 6/100\n",
      "7982/7982 [==============================] - 0s 33us/step - loss: 0.8261 - mean_squared_error: 0.8261 - mean_absolute_error: 0.6156\n",
      "Epoch 7/100\n",
      "7982/7982 [==============================] - 0s 30us/step - loss: 0.8404 - mean_squared_error: 0.8404 - mean_absolute_error: 0.6261\n",
      "Epoch 8/100\n",
      "7982/7982 [==============================] - 0s 31us/step - loss: 0.8081 - mean_squared_error: 0.8081 - mean_absolute_error: 0.6097\n",
      "Epoch 9/100\n",
      "7982/7982 [==============================] - 0s 30us/step - loss: 0.8654 - mean_squared_error: 0.8654 - mean_absolute_error: 0.6349\n",
      "Epoch 10/100\n",
      "7982/7982 [==============================] - 0s 30us/step - loss: 0.8633 - mean_squared_error: 0.8633 - mean_absolute_error: 0.6377\n",
      "Epoch 11/100\n",
      "7982/7982 [==============================] - 0s 30us/step - loss: 0.8626 - mean_squared_error: 0.8626 - mean_absolute_error: 0.6376\n",
      "Epoch 12/100\n",
      "7982/7982 [==============================] - 0s 31us/step - loss: 0.8507 - mean_squared_error: 0.8507 - mean_absolute_error: 0.6293\n",
      "Epoch 13/100\n",
      "7982/7982 [==============================] - 0s 29us/step - loss: 0.8638 - mean_squared_error: 0.8638 - mean_absolute_error: 0.6380\n",
      "Epoch 14/100\n",
      "7982/7982 [==============================] - 0s 30us/step - loss: 0.9965 - mean_squared_error: 0.9965 - mean_absolute_error: 0.7002\n",
      "Epoch 15/100\n",
      "7982/7982 [==============================] - 0s 33us/step - loss: 1.0324 - mean_squared_error: 1.0324 - mean_absolute_error: 0.7097\n",
      "Epoch 16/100\n",
      "7982/7982 [==============================] - 0s 33us/step - loss: 0.8843 - mean_squared_error: 0.8843 - mean_absolute_error: 0.6478\n",
      "Epoch 17/100\n",
      "7982/7982 [==============================] - 0s 34us/step - loss: 0.9075 - mean_squared_error: 0.9075 - mean_absolute_error: 0.6547\n",
      "Epoch 18/100\n",
      "7982/7982 [==============================] - 0s 30us/step - loss: 1.0130 - mean_squared_error: 1.0130 - mean_absolute_error: 0.7098\n",
      "Epoch 19/100\n",
      "7982/7982 [==============================] - 0s 30us/step - loss: 0.9579 - mean_squared_error: 0.9579 - mean_absolute_error: 0.6863\n",
      "Epoch 20/100\n",
      "7982/7982 [==============================] - 0s 29us/step - loss: 1.0416 - mean_squared_error: 1.0416 - mean_absolute_error: 0.7220\n",
      "Epoch 21/100\n",
      "7982/7982 [==============================] - 0s 34us/step - loss: 1.1473 - mean_squared_error: 1.1473 - mean_absolute_error: 0.7589\n",
      "Epoch 22/100\n",
      "7982/7982 [==============================] - 0s 33us/step - loss: 1.0247 - mean_squared_error: 1.0247 - mean_absolute_error: 0.7154\n",
      "Epoch 23/100\n",
      "7982/7982 [==============================] - 0s 33us/step - loss: 1.1377 - mean_squared_error: 1.1377 - mean_absolute_error: 0.7556\n",
      "Epoch 24/100\n",
      "7982/7982 [==============================] - 0s 34us/step - loss: 0.9442 - mean_squared_error: 0.9442 - mean_absolute_error: 0.6806\n",
      "Epoch 25/100\n",
      "7982/7982 [==============================] - 0s 36us/step - loss: 1.0554 - mean_squared_error: 1.0554 - mean_absolute_error: 0.7224\n",
      "Epoch 26/100\n",
      "7982/7982 [==============================] - 0s 32us/step - loss: 1.0641 - mean_squared_error: 1.0641 - mean_absolute_error: 0.7280\n",
      "Epoch 27/100\n",
      "7982/7982 [==============================] - 0s 32us/step - loss: 1.2025 - mean_squared_error: 1.2025 - mean_absolute_error: 0.7744\n",
      "Epoch 28/100\n",
      "7982/7982 [==============================] - 0s 30us/step - loss: 1.0711 - mean_squared_error: 1.0711 - mean_absolute_error: 0.7296\n",
      "Epoch 29/100\n",
      "7982/7982 [==============================] - 0s 34us/step - loss: 0.9879 - mean_squared_error: 0.9879 - mean_absolute_error: 0.6936\n",
      "Epoch 30/100\n",
      "7982/7982 [==============================] - 0s 32us/step - loss: 1.0717 - mean_squared_error: 1.0717 - mean_absolute_error: 0.7254\n",
      "Epoch 31/100\n",
      "7982/7982 [==============================] - 0s 32us/step - loss: 1.2722 - mean_squared_error: 1.2722 - mean_absolute_error: 0.7945\n",
      "Epoch 32/100\n",
      "7982/7982 [==============================] - 0s 30us/step - loss: 1.2041 - mean_squared_error: 1.2041 - mean_absolute_error: 0.7850\n",
      "Epoch 33/100\n",
      "7982/7982 [==============================] - 0s 30us/step - loss: 1.0820 - mean_squared_error: 1.0820 - mean_absolute_error: 0.7318\n",
      "Epoch 34/100\n",
      "7982/7982 [==============================] - 0s 31us/step - loss: 1.3842 - mean_squared_error: 1.3842 - mean_absolute_error: 0.8304\n",
      "Epoch 35/100\n",
      "7982/7982 [==============================] - 0s 29us/step - loss: 1.1737 - mean_squared_error: 1.1737 - mean_absolute_error: 0.7572\n",
      "Epoch 36/100\n",
      "7982/7982 [==============================] - 0s 33us/step - loss: 0.9433 - mean_squared_error: 0.9433 - mean_absolute_error: 0.6746\n",
      "Epoch 37/100\n",
      "7982/7982 [==============================] - 0s 28us/step - loss: 0.9683 - mean_squared_error: 0.9683 - mean_absolute_error: 0.6857\n",
      "Epoch 38/100\n",
      "7982/7982 [==============================] - 0s 32us/step - loss: 1.0105 - mean_squared_error: 1.0105 - mean_absolute_error: 0.7084\n",
      "Epoch 39/100\n",
      "7982/7982 [==============================] - 0s 31us/step - loss: 0.9980 - mean_squared_error: 0.9980 - mean_absolute_error: 0.7022\n",
      "Epoch 40/100\n",
      "7982/7982 [==============================] - 0s 33us/step - loss: 1.0345 - mean_squared_error: 1.0345 - mean_absolute_error: 0.7128\n",
      "Epoch 41/100\n",
      "7982/7982 [==============================] - 0s 31us/step - loss: 0.9928 - mean_squared_error: 0.9928 - mean_absolute_error: 0.7015\n",
      "Epoch 42/100\n",
      "7982/7982 [==============================] - 0s 32us/step - loss: 1.3518 - mean_squared_error: 1.3518 - mean_absolute_error: 0.8472\n",
      "Epoch 43/100\n",
      "7982/7982 [==============================] - 0s 30us/step - loss: 1.3269 - mean_squared_error: 1.3269 - mean_absolute_error: 0.8203\n",
      "Epoch 44/100\n",
      "7982/7982 [==============================] - 0s 34us/step - loss: 0.9730 - mean_squared_error: 0.9730 - mean_absolute_error: 0.6910\n",
      "Epoch 45/100\n",
      "7982/7982 [==============================] - 0s 34us/step - loss: 0.9560 - mean_squared_error: 0.9560 - mean_absolute_error: 0.6807\n",
      "Epoch 46/100\n",
      "7982/7982 [==============================] - 0s 32us/step - loss: 1.0799 - mean_squared_error: 1.0799 - mean_absolute_error: 0.7274\n",
      "Epoch 47/100\n",
      "7982/7982 [==============================] - 0s 31us/step - loss: 0.9391 - mean_squared_error: 0.9391 - mean_absolute_error: 0.6768\n",
      "Epoch 48/100\n",
      "7982/7982 [==============================] - 0s 31us/step - loss: 0.9910 - mean_squared_error: 0.9910 - mean_absolute_error: 0.6974\n",
      "Epoch 49/100\n",
      "7982/7982 [==============================] - 0s 29us/step - loss: 1.1210 - mean_squared_error: 1.1210 - mean_absolute_error: 0.7578\n",
      "Epoch 50/100\n",
      "7982/7982 [==============================] - 0s 30us/step - loss: 0.9096 - mean_squared_error: 0.9096 - mean_absolute_error: 0.6590\n",
      "Epoch 51/100\n",
      "7982/7982 [==============================] - 0s 28us/step - loss: 1.2604 - mean_squared_error: 1.2604 - mean_absolute_error: 0.8019\n",
      "Epoch 52/100\n",
      "7982/7982 [==============================] - 0s 33us/step - loss: 0.9528 - mean_squared_error: 0.9528 - mean_absolute_error: 0.6809\n",
      "Epoch 53/100\n",
      "7982/7982 [==============================] - 0s 28us/step - loss: 1.2008 - mean_squared_error: 1.2008 - mean_absolute_error: 0.7901\n",
      "Epoch 54/100\n",
      "7982/7982 [==============================] - 0s 32us/step - loss: 1.2263 - mean_squared_error: 1.2263 - mean_absolute_error: 0.7886\n",
      "Epoch 55/100\n",
      "7982/7982 [==============================] - 0s 30us/step - loss: 1.1092 - mean_squared_error: 1.1092 - mean_absolute_error: 0.7468\n",
      "Epoch 56/100\n",
      "7982/7982 [==============================] - 0s 30us/step - loss: 0.9708 - mean_squared_error: 0.9708 - mean_absolute_error: 0.6948\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7982/7982 [==============================] - 0s 31us/step - loss: 0.9577 - mean_squared_error: 0.9577 - mean_absolute_error: 0.6893\n",
      "Epoch 58/100\n",
      "7982/7982 [==============================] - 0s 28us/step - loss: 0.8360 - mean_squared_error: 0.8360 - mean_absolute_error: 0.6266\n",
      "Epoch 59/100\n",
      "7982/7982 [==============================] - 0s 28us/step - loss: 1.4349 - mean_squared_error: 1.4349 - mean_absolute_error: 0.8693\n",
      "Epoch 60/100\n",
      "7982/7982 [==============================] - 0s 32us/step - loss: 1.2237 - mean_squared_error: 1.2237 - mean_absolute_error: 0.7835\n",
      "Epoch 61/100\n",
      "7982/7982 [==============================] - 0s 28us/step - loss: 0.9782 - mean_squared_error: 0.9782 - mean_absolute_error: 0.6926\n",
      "Epoch 62/100\n",
      "7982/7982 [==============================] - 0s 29us/step - loss: 0.9603 - mean_squared_error: 0.9603 - mean_absolute_error: 0.6857\n",
      "Epoch 63/100\n",
      "7982/7982 [==============================] - 0s 28us/step - loss: 1.0657 - mean_squared_error: 1.0657 - mean_absolute_error: 0.7367\n",
      "Epoch 64/100\n",
      "7982/7982 [==============================] - 0s 28us/step - loss: 1.2775 - mean_squared_error: 1.2775 - mean_absolute_error: 0.8116\n",
      "Epoch 65/100\n",
      "7982/7982 [==============================] - 0s 29us/step - loss: 0.8737 - mean_squared_error: 0.8737 - mean_absolute_error: 0.6445\n",
      "Epoch 66/100\n",
      "7982/7982 [==============================] - 0s 32us/step - loss: 0.8485 - mean_squared_error: 0.8485 - mean_absolute_error: 0.6343\n",
      "Epoch 67/100\n",
      "7982/7982 [==============================] - 0s 32us/step - loss: 1.2661 - mean_squared_error: 1.2661 - mean_absolute_error: 0.7957\n",
      "Epoch 68/100\n",
      "7982/7982 [==============================] - 0s 31us/step - loss: 0.9949 - mean_squared_error: 0.9949 - mean_absolute_error: 0.7049\n",
      "Epoch 69/100\n",
      "7982/7982 [==============================] - 0s 32us/step - loss: 0.9902 - mean_squared_error: 0.9902 - mean_absolute_error: 0.6996\n",
      "Epoch 70/100\n",
      "7982/7982 [==============================] - 0s 31us/step - loss: 1.2128 - mean_squared_error: 1.2128 - mean_absolute_error: 0.7783\n",
      "Epoch 71/100\n",
      "7982/7982 [==============================] - 0s 31us/step - loss: 0.9648 - mean_squared_error: 0.9648 - mean_absolute_error: 0.6860\n",
      "Epoch 72/100\n",
      "7982/7982 [==============================] - 0s 33us/step - loss: 1.1565 - mean_squared_error: 1.1565 - mean_absolute_error: 0.7511\n",
      "Epoch 73/100\n",
      "7982/7982 [==============================] - 0s 32us/step - loss: 1.0612 - mean_squared_error: 1.0612 - mean_absolute_error: 0.7272\n",
      "Epoch 74/100\n",
      "7982/7982 [==============================] - 0s 34us/step - loss: 0.9157 - mean_squared_error: 0.9157 - mean_absolute_error: 0.6673\n",
      "Epoch 75/100\n",
      "7982/7982 [==============================] - 0s 31us/step - loss: 0.9556 - mean_squared_error: 0.9556 - mean_absolute_error: 0.6864\n",
      "Epoch 76/100\n",
      "7982/7982 [==============================] - 0s 34us/step - loss: 1.1181 - mean_squared_error: 1.1181 - mean_absolute_error: 0.7572\n",
      "Epoch 77/100\n",
      "7982/7982 [==============================] - 0s 33us/step - loss: 0.8732 - mean_squared_error: 0.8732 - mean_absolute_error: 0.6518\n",
      "Epoch 78/100\n",
      "7982/7982 [==============================] - 0s 33us/step - loss: 0.8512 - mean_squared_error: 0.8512 - mean_absolute_error: 0.6436\n",
      "Epoch 79/100\n",
      "7982/7982 [==============================] - 0s 33us/step - loss: 0.8499 - mean_squared_error: 0.8499 - mean_absolute_error: 0.6438\n",
      "Epoch 80/100\n",
      "7982/7982 [==============================] - 0s 32us/step - loss: 1.1060 - mean_squared_error: 1.1060 - mean_absolute_error: 0.7489\n",
      "Epoch 81/100\n",
      "7982/7982 [==============================] - 0s 31us/step - loss: 1.1177 - mean_squared_error: 1.1177 - mean_absolute_error: 0.7594\n",
      "Epoch 82/100\n",
      "7982/7982 [==============================] - 0s 34us/step - loss: 0.9528 - mean_squared_error: 0.9528 - mean_absolute_error: 0.6807\n",
      "Epoch 83/100\n",
      "7982/7982 [==============================] - 0s 32us/step - loss: 0.9721 - mean_squared_error: 0.9721 - mean_absolute_error: 0.6968\n",
      "Epoch 84/100\n",
      "7982/7982 [==============================] - 0s 34us/step - loss: 0.8523 - mean_squared_error: 0.8523 - mean_absolute_error: 0.6459\n",
      "Epoch 85/100\n",
      "7982/7982 [==============================] - 0s 31us/step - loss: 1.1869 - mean_squared_error: 1.1869 - mean_absolute_error: 0.7864\n",
      "Epoch 86/100\n",
      "7982/7982 [==============================] - 0s 31us/step - loss: 0.9237 - mean_squared_error: 0.9237 - mean_absolute_error: 0.6844\n",
      "Epoch 87/100\n",
      "7982/7982 [==============================] - 0s 33us/step - loss: 0.9795 - mean_squared_error: 0.9795 - mean_absolute_error: 0.7034\n",
      "Epoch 88/100\n",
      "7982/7982 [==============================] - 0s 32us/step - loss: 0.9585 - mean_squared_error: 0.9585 - mean_absolute_error: 0.6910\n",
      "Epoch 89/100\n",
      "7982/7982 [==============================] - 0s 27us/step - loss: 0.8861 - mean_squared_error: 0.8861 - mean_absolute_error: 0.6636\n",
      "Epoch 90/100\n",
      "7982/7982 [==============================] - 0s 29us/step - loss: 0.8761 - mean_squared_error: 0.8761 - mean_absolute_error: 0.6576\n",
      "Epoch 91/100\n",
      "7982/7982 [==============================] - 0s 30us/step - loss: 1.0113 - mean_squared_error: 1.0113 - mean_absolute_error: 0.7185\n",
      "Epoch 92/100\n",
      "7982/7982 [==============================] - 0s 32us/step - loss: 0.8773 - mean_squared_error: 0.8773 - mean_absolute_error: 0.6616\n",
      "Epoch 93/100\n",
      "7982/7982 [==============================] - 0s 29us/step - loss: 0.9666 - mean_squared_error: 0.9666 - mean_absolute_error: 0.6932\n",
      "Epoch 94/100\n",
      "7982/7982 [==============================] - 0s 30us/step - loss: 1.3293 - mean_squared_error: 1.3293 - mean_absolute_error: 0.8293\n",
      "Epoch 95/100\n",
      "7982/7982 [==============================] - 0s 30us/step - loss: 0.8109 - mean_squared_error: 0.8109 - mean_absolute_error: 0.6227\n",
      "Epoch 96/100\n",
      "7982/7982 [==============================] - 0s 30us/step - loss: 1.0030 - mean_squared_error: 1.0030 - mean_absolute_error: 0.7174\n",
      "Epoch 97/100\n",
      "7982/7982 [==============================] - 0s 31us/step - loss: 0.9270 - mean_squared_error: 0.9270 - mean_absolute_error: 0.6848\n",
      "Epoch 98/100\n",
      "7982/7982 [==============================] - 0s 30us/step - loss: 1.0367 - mean_squared_error: 1.0367 - mean_absolute_error: 0.7153\n",
      "Epoch 99/100\n",
      "7982/7982 [==============================] - 0s 34us/step - loss: 0.8958 - mean_squared_error: 0.8958 - mean_absolute_error: 0.6750\n",
      "Epoch 100/100\n",
      "7982/7982 [==============================] - 0s 30us/step - loss: 0.9155 - mean_squared_error: 0.9155 - mean_absolute_error: 0.6726\n",
      "1996/1996 [==============================] - 0s 34us/step\n",
      "MSE: 1.5339680910110474, MAE: 1.013108730316162\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim = X.shape[1], activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer = 'adam', metrics=['mean_squared_error','mean_absolute_error'])\n",
    "model.fit(X, y, epochs = 1000, batch_size = 16)\n",
    "\n",
    "_, MSE, MAE = model.evaluate(Xt, yt)\n",
    "print('MSE: ' + str(MSE) + ', MAE: '+ str(MAE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Bias of Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE:  1.533967943681707\n",
      "Test MAE:  1.0131087721948757\n"
     ]
    }
   ],
   "source": [
    "test_predicted = model.predict(Xt)\n",
    "mse = mean_squared_error(yt, test_predicted)\n",
    "print(\"Test MSE: \",mse)\n",
    "mae = mean_absolute_error(yt, test_predicted)\n",
    "print(\"Test MAE: \",mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset to Visualize Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_data = pd.read_csv(\"census_block_loc.csv\")\n",
    "block_data = block_data.drop(columns=[\"BlockCode\",\"County\",\"State\"])\n",
    "block_data[\"Raw_Bias\"]=np.random.normal(scale=10,size=block_data.shape[0])\n",
    "block_data[\"County_Bias\"]=np.random.normal(scale=1,size=block_data.shape[0])\n",
    "block_data[\"Smoothed_Bias\"]=np.random.normal(scale=5,size=block_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put in visuals here from the dataset \"block_data\"\n",
    "#real data will be replaced when Erik figures out the proper way to do the smoothing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
